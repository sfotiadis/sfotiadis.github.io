---
layout: post
title: 'I am a published scientist. '
date: '2013-09-06T13:32:00.002+02:00'
author: kabamaru
tags:
- human detection
- firefly
- computer vision
- hokuyo
- paper
- science
- machine learning
modified_time: '2013-09-06T14:30:47.480+02:00'
thumbnail: http://1.bp.blogspot.com/-HrVKSW0Hmtc/Uim0sjGQXdI/AAAAAAAAAcc/g-QqLhE7Azo/s72-c/DSC_9019.JPG
blogger_id: tag:blogger.com,1999:blog-950788785801424157.post-5036198919291485009
blogger_orig_url: http://blog.fotiad.is/2013/09/i-am-published-scientist.html
redirect_from:
- http://blog.fotiad.is/2013/09/i-am-published-scientist.html/
- http://kabamaru.blogspot.com/2013/09/i-am-published-scientist.html/
---

<div dir="ltr" style="text-align: left;" trbidi="on">This post is to celebrate the publication of my first scientific paper. After a year of hard work it's out there, on the loose. A tiny contribution to the vast corpus of human knowledge. I must admit it's really satisfying.&nbsp;Minus one on the bucket list.<br /><br />In a few words, the goal was to build a real-time system for human detection in order to be used on board a medium sized mobile robot, the Summit XL(c) by Robotnik(c).<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-HrVKSW0Hmtc/Uim0sjGQXdI/AAAAAAAAAcc/g-QqLhE7Azo/s1600/DSC_9019.JPG" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img alt="Summit XL" border="0" height="265" src="http://1.bp.blogspot.com/-HrVKSW0Hmtc/Uim0sjGQXdI/AAAAAAAAAcc/g-QqLhE7Azo/s400/DSC_9019.JPG" title="Summit XL" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Summit XL(c)</td></tr></tbody></table>The task was accomplished by using two sensors: a Hokuyo UTM-30LX-EW(c) and a PointGrey Firefly MV(c) camera. The information from the two sensors was synchronously fused in order to produce greater accuracy. The technical details can be seen on the <a href="http://www.mdpi.com/1424-8220/13/9/11603" target="_blank">paper</a>&nbsp;which was published on the&nbsp;&nbsp;Sensors journal. It has an&nbsp;<i><a href="http://www.mdpi.com/about/openaccess" target="_blank">open access</a>&nbsp;</i>policy which is very important for the dissemination of knowledge, but that's another discussion.<br /><div><br /></div><div>The system was initially prototyped with Matlab(c) and Python. The real-time version was later developed in C++ using the <a href="http://wiki.ros.org/" target="_blank">Robot Operating System</a> and <a href="http://opencv.org/" target="_blank">OpenCV</a> libraries. The source code has been released on&nbsp;<a href="https://github.com/kabamarulis/hdetect/" target="_blank">github</a> and there are plans to create an official ROS package of our group in <a href="http://robcib.etsii.upm.es/" target="_blank">UPM</a>.&nbsp;Speaking of which I am really happy to have worked with colleagues such as Mario, Antonio, Andr√©s and Pablo here.</div><div><br /><div>Some of the results can be seen in the following video:<br /><div class="separator" style="clear: both; text-align: center;"><br /></div><div style="text-align: center;"><object class="BLOGGER-youtube-video" classid="clsid:D27CDB6E-AE6D-11cf-96B8-444553540000" codebase="http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0" data-thumbnail-src="http://i1.ytimg.com/vi/-pk3-RhiXSE/0.jpg" height="360" width="640"><param name="movie" value="http://www.youtube.com/v/-pk3-RhiXSE?version=3&f=user_uploads&c=google-webdrive-0&app=youtube_gdata" /><param name="bgcolor" value="#FFFFFF" /><param name="allowFullScreen" value="true" /><embed width="640" height="360"  src="http://www.youtube.com/v/-pk3-RhiXSE?version=3&vq=large&f=user_uploads&c=google-webdrive-0&app=youtube_gdata" type="application/x-shockwave-flash" allowfullscreen="true"></embed></object></div><div><br /></div></div></div></div>