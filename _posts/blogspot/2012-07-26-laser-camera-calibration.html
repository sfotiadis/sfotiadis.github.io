---
layout: post
title: Laser-camera calibration
date: '2012-07-26T17:16:00.000+02:00'
author: kabamaru
tags:
- firefly
- 3d printer
- hokuyo
- calibration
- matlab
modified_time: '2013-09-06T14:55:42.324+02:00'
thumbnail: http://1.bp.blogspot.com/-Le8wSeVLwWY/UBFeLw0YgFI/AAAAAAAAAYM/r2cNn1o3s5s/s72-c/hokuyo-firefly.jpg
blogger_id: tag:blogger.com,1999:blog-950788785801424157.post-6662725855373214673
blogger_orig_url: http://blog.fotiad.is/2012/07/laser-camera-calibration.html
---

<div dir="ltr" style="text-align: left;" trbidi="on"><table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: right; margin-left: 1em; text-align: right;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-Le8wSeVLwWY/UBFeLw0YgFI/AAAAAAAAAYM/r2cNn1o3s5s/s1600/hokuyo-firefly.jpg" imageanchor="1" style="clear: right; margin-bottom: 1em; margin-left: auto; margin-right: auto;"><img border="0" height="239" src="http://1.bp.blogspot.com/-Le8wSeVLwWY/UBFeLw0YgFI/AAAAAAAAAYM/r2cNn1o3s5s/s320/hokuyo-firefly.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Hokuyo URG-04-LX &amp; Firefly-MV</td></tr></tbody></table>In my project I use a simple <a href="http://kabamaru.blogspot.com.es/2012/06/how-to-use-firefly-mv-camera-on-matlab.html" target="_blank">firefly-mv camera</a> and a laser range finder from Hokuyo. The laser that I use now is UTM-30-LX-EW instead of the previously used URG-04-LX. <strike>More details here</strike>.These two sensors are placed on a moving robot and they are used in conjuction to detect pedestrians (and other moving objects &nbsp;in the future). Since we use data from both sensors to extract information about the presence of a pedestrin, we need an accurate way of correlating, both in space and time, those two signals. Solving the time issue is trivial with the use of timestamps which give adequate accuracy for objects moving at relatively low speeds.<br /><div>But for the space correlation things are more complex. The camera singal is a projection of a 3d plane into 2d and the laser signal is a 1d scan from the 3d world. So if you want to know which points are corresponding you have to know the exact 'difference' between the point of view of the two sensors. That is we need to know the exact transformation matrix between the laser and the camera. This process is called laser-camera calibration. And to do it we are going to use a neat matlab toolbox developed by A. Kassir[3].</div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-B1PpUxcnt0I/UBFRLqGmapI/AAAAAAAAAXw/MgghCACAAgo/s1600/Screen+Shot+2012-06-27+at+17.08.41.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="237" src="http://2.bp.blogspot.com/-B1PpUxcnt0I/UBFRLqGmapI/AAAAAAAAAXw/MgghCACAAgo/s400/Screen+Shot+2012-06-27+at+17.08.41.png" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Figure1. <br />Detected corners on the checkerboard</td></tr></tbody></table><div>First we begin with intrisincally calibrating the camera[1]. The optics and electronics of the camera are far from perfect, so some distortion is apparent. What we need to find is the distortion coefficients so we can later "repair" each camera image. To do this we use a checkerboard pattern with known dimensions. We use the checkerboard because it's easy to detect the corners and thus compute the plane in which they belong (see Fig 1). For more accurate results we have to move the checkerboard into various positions and orientations (Fig 2).&nbsp;</div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-74u20k75KhM/UBFRMKNNskI/AAAAAAAAAX0/lIUOxFeInAE/s1600/camera+calibration.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="316" src="http://2.bp.blogspot.com/-74u20k75KhM/UBFRMKNNskI/AAAAAAAAAX0/lIUOxFeInAE/s640/camera+calibration.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Figure2. <br />The algorithm extracted the various positions of the checkerboard</td></tr></tbody></table><div>After the camera is intrinsically calibrated, next comes the extrinsic laser-camera calibration which will give the distance and rotation between the two sensors. For this we have already recorder laser scans for each camera photo grabbed. The laser segment that corresponds to the checkerboard is automatically extracted [3] and the problem left to solve is how to minimize the algebraic distance of the two measurements. Which is a linear problem and can easily be solved with <a href="http://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)" target="_blank">least squares.</a>&nbsp;A non-linear method based on the plane orientation is also used, along with a global optimization step including all the poses of the checkeboard [2]. After we get our results we can superimpose laser scans on images.<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-WgVXY7Smyqc/UBFc7kav_HI/AAAAAAAAAYE/WLRTd_6IBMA/s1600/Screen+Shot+2012-07-26+at+17.05.28.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://1.bp.blogspot.com/-WgVXY7Smyqc/UBFc7kav_HI/AAAAAAAAAYE/WLRTd_6IBMA/s1600/Screen+Shot+2012-07-26+at+17.05.28.png" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Laser segments superimposed on the camera image</td></tr></tbody></table>The calibration is not so easy two be done and the results sometimes are subpar what is really necessary. One detail I can't stress more is the need for a <b>really firm base </b>to keep the camera and the laser from moving in relation to each other. The good news is that if you have a 3d printer you can easily design and print your own base. We (Mario that is) designed two bases one for the urg-04-lx and one for the utm-30-lx-ew, the camera is firefly-mv for both. You can download them <a href="https://www.dropbox.com/s/er0gatvia1tjxvk/Laser_bases.zip" target="_blank">here</a>&nbsp;in ipt (autodesk inventor) and stl format, in case anyone finds them useful (yes I'm refering to you my future self).<br /><br /><br /><a href="http://www.vision.caltech.edu/bouguetj/calib_doc/" target="_blank">[1]. J.-Y. Bouguet. Camera Calibration Toolbox for Matlab, 2009</a>&nbsp;</div><div><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1389752&amp;tag=1" target="_blank">[2] Q. Zhang and R. Pless. Extrinsic calibration of a camera and laser range finder (improves camera calibration). In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, 2004</a></div><div><a href="http://www-personal.acfr.usyd.edu.au/akas9185/AutoCalib/index.html" target="_blank">[3]. A. Kassir and T. Peynot. Reliable Automatic Camera-Laser Calibration (Matlab toolbox), 2010</a><br /><br /></div></div>